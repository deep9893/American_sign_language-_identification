{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AkKxOxayJgQ",
    "papermill": {
     "duration": 0.015851,
     "end_time": "2021-01-14T14:45:43.954922",
     "exception": false,
     "start_time": "2021-01-14T14:45:43.939071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Introduction: Business Goal & Problem Definition\n",
    "\n",
    "This projects goal is developing a deep learning model able to identify American Sign photos, so in the future we can automatically identify those signs and help deaf people communicate. I´m using a Kaggle dataset containing 2515 photos showing all digits from 0 to 9 and all alphabet letters from a to z.\n",
    "\n",
    "IF YOU LIKE IT OR IF IT HELPS YOU SOMEHOW, COULD YOU PLEASE UPVOTE? THANK YOU VERY MUCH!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFgjKzuayJgW",
    "papermill": {
     "duration": 0.0123,
     "end_time": "2021-01-14T14:45:43.980584",
     "exception": false,
     "start_time": "2021-01-14T14:45:43.968284",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Importing Basic Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-14T14:45:44.013431Z",
     "iopub.status.busy": "2021-01-14T14:45:44.012580Z",
     "iopub.status.idle": "2021-01-14T14:45:51.881115Z",
     "shell.execute_reply": "2021-01-14T14:45:51.879505Z"
    },
    "id": "DSb1VijtyJgW",
    "papermill": {
     "duration": 7.888169,
     "end_time": "2021-01-14T14:45:51.881300",
     "exception": false,
     "start_time": "2021-01-14T14:45:43.993131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOI1aUdgyJgX",
    "papermill": {
     "duration": 0.01206,
     "end_time": "2021-01-14T14:45:51.906259",
     "exception": false,
     "start_time": "2021-01-14T14:45:51.894199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-14T14:45:51.940732Z",
     "iopub.status.busy": "2021-01-14T14:45:51.939716Z",
     "iopub.status.idle": "2021-01-14T14:46:14.262589Z",
     "shell.execute_reply": "2021-01-14T14:46:14.263130Z"
    },
    "id": "q0Zngo8QyJgX",
    "outputId": "bea469d7-6371-4dc1-97a6-f4055a82a1d5",
    "papermill": {
     "duration": 22.344535,
     "end_time": "2021-01-14T14:46:14.263319",
     "exception": false,
     "start_time": "2021-01-14T14:45:51.918784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Copying current content to new editable directory\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      4\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#Selecting dataset directory\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "#Copying current content to new editable directory\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive/')\n",
    "#Selecting dataset directory\n",
    "\n",
    "ds_asl_dir = '/content/drive/MyDrive/Colab Notebooks/Hand gesture recognition/asl_dataset'\n",
    "\n",
    "#Generating a dataset\n",
    "\n",
    "asl_ds = tf.keras.preprocessing.image_dataset_from_directory(ds_asl_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyJd2J6ryJgY",
    "papermill": {
     "duration": 0.012967,
     "end_time": "2021-01-14T14:46:14.289813",
     "exception": false,
     "start_time": "2021-01-14T14:46:14.276846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Data Preliminary Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2021-01-14T14:46:14.320139Z",
     "iopub.status.busy": "2021-01-14T14:46:14.319439Z",
     "iopub.status.idle": "2021-01-14T14:46:15.098696Z",
     "shell.execute_reply": "2021-01-14T14:46:15.098072Z"
    },
    "id": "vU0ETe7AyJgY",
    "outputId": "b0d64199-bced-4800-c485-ebf0c486b48a",
    "papermill": {
     "duration": 0.795983,
     "end_time": "2021-01-14T14:46:15.098846",
     "exception": false,
     "start_time": "2021-01-14T14:46:14.302863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"none\"\n",
    "\n",
    "#Listing directory. You can find the class names in the class_names attribute on these datasets. These correspond to the directory names in alphabetical order.\n",
    "\n",
    "!ls '/content/drive/MyDrive/Colab Notebooks/Hand gesture recognition/asl_dataset'\n",
    "\n",
    "#Showing index + class\n",
    "\n",
    "pd.DataFrame(asl_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-14T14:46:15.131985Z",
     "iopub.status.busy": "2021-01-14T14:46:15.131249Z",
     "iopub.status.idle": "2021-01-14T14:46:15.978008Z",
     "shell.execute_reply": "2021-01-14T14:46:15.979176Z"
    },
    "id": "SEbA4X1_yJgZ",
    "outputId": "dbd39a5f-8ddc-4782-eb22-b31c1dce4006",
    "papermill": {
     "duration": 0.865926,
     "end_time": "2021-01-14T14:46:15.979366",
     "exception": false,
     "start_time": "2021-01-14T14:46:15.113440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Checking images and labels shapes (amount of images, height, width, color channels)\n",
    "\n",
    "for image_batch, labels_batch in asl_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "execution": {
     "iopub.execute_input": "2021-01-14T14:46:16.079886Z",
     "iopub.status.busy": "2021-01-14T14:46:16.079151Z",
     "iopub.status.idle": "2021-01-14T14:46:17.250357Z",
     "shell.execute_reply": "2021-01-14T14:46:17.250882Z"
    },
    "id": "_ZFyZWVsyJgZ",
    "outputId": "e5e56f85-579e-489e-83b4-d540178995da",
    "papermill": {
     "duration": 1.190316,
     "end_time": "2021-01-14T14:46:17.251020",
     "exception": false,
     "start_time": "2021-01-14T14:46:16.060704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Displaying image samples\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in asl_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8vWFjJxyJgZ",
    "papermill": {
     "duration": 0.022654,
     "end_time": "2021-01-14T14:46:17.297975",
     "exception": false,
     "start_time": "2021-01-14T14:46:17.275321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-14T14:46:17.385756Z",
     "iopub.status.busy": "2021-01-14T14:46:17.379685Z",
     "iopub.status.idle": "2021-01-14T14:46:17.736839Z",
     "shell.execute_reply": "2021-01-14T14:46:17.737445Z"
    },
    "id": "t79kRSNkyJga",
    "outputId": "be9af92d-60fe-427c-bad6-ce4089b55780",
    "papermill": {
     "duration": 0.389642,
     "end_time": "2021-01-14T14:46:17.737615",
     "exception": false,
     "start_time": "2021-01-14T14:46:17.347973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Defining parameters for the loader\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 64\n",
    "img_width = 64\n",
    "\n",
    "#Filtering out corrupted images\n",
    "\n",
    "import os\n",
    "num_skipped = 0\n",
    "for folder_name in (\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\"\n",
    "                    ,\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"):\n",
    "    folder_path = os.path.join(ds_asl_dir, folder_name)\n",
    "    for fname in os.listdir(folder_path):\n",
    "        fpath = os.path.join(folder_path, fname)\n",
    "        try:\n",
    "            fobj = open(fpath, \"rb\")\n",
    "            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
    "        finally:\n",
    "            fobj.close()\n",
    "        if not is_jfif:\n",
    "            num_skipped += 1\n",
    "            # Delete corrupted image\n",
    "            os.remove(fpath)\n",
    "print(\"Deleted %d images\" % num_skipped)\n",
    "\n",
    "#Augmenting the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "data_augmentation = ImageDataGenerator(rotation_range=15, rescale=1/255, zoom_range=0.1, horizontal_flip=True,\n",
    "                                       width_shift_range=0.1, height_shift_range=0.1, validation_split=0.2)\n",
    "\n",
    "#Setting train/test split\n",
    "\n",
    "asl_train_ds = data_augmentation.flow_from_directory(directory=ds_asl_dir, target_size=(img_height, img_width),\n",
    "                                                     class_mode=\"categorical\", batch_size=batch_size, subset=\"training\")\n",
    "asl_test_ds = data_augmentation.flow_from_directory(directory=ds_asl_dir, target_size=(img_height, img_width),\n",
    "                                                    class_mode=\"categorical\", batch_size=batch_size, subset=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVySgi2oyJga",
    "papermill": {
     "duration": 0.021923,
     "end_time": "2021-01-14T14:46:17.781839",
     "exception": false,
     "start_time": "2021-01-14T14:46:17.759916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-14T14:46:17.842185Z",
     "iopub.status.busy": "2021-01-14T14:46:17.841276Z",
     "iopub.status.idle": "2021-01-14T14:46:17.982676Z",
     "shell.execute_reply": "2021-01-14T14:46:17.982059Z"
    },
    "id": "P-BIs73NyJga",
    "papermill": {
     "duration": 0.178373,
     "end_time": "2021-01-14T14:46:17.982817",
     "exception": false,
     "start_time": "2021-01-14T14:46:17.804444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D,MaxPool2D,Dropout,Flatten,Dense\n",
    "\n",
    "#Checking if the data format i.e the RGB channel is coming first or last so, whatever it may be, model will check first and then input shape will be feeded accordingly.\n",
    "\n",
    "from keras import backend as K\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    input_shape = (3, img_height, img_width)\n",
    "else:\n",
    "    input_shape = (img_height, img_width, 3)\n",
    "\n",
    "#Creating a model\n",
    "\n",
    "model_dl = keras.Sequential()\n",
    "model_dl.add(Conv2D(16,(3,3),activation=\"relu\",input_shape=(input_shape)))\n",
    "model_dl.add(MaxPool2D(2,2))\n",
    "model_dl.add(Dropout(0.2))\n",
    "model_dl.add(Conv2D(32,(3,3),activation=\"relu\"))\n",
    "model_dl.add(MaxPool2D(2,2))\n",
    "model_dl.add(Dropout(0.2))\n",
    "model_dl.add(Conv2D(64,(3,3),activation=\"relu\"))\n",
    "model_dl.add(MaxPool2D(2,2))\n",
    "model_dl.add(Dropout(0.2))\n",
    "model_dl.add(Flatten())\n",
    "model_dl.add(Dense(128,activation=\"relu\"))\n",
    "model_dl.add(Dropout(0.2))\n",
    "model_dl.add(Dense(36,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdgpNi5OyJgb",
    "papermill": {
     "duration": 0.022293,
     "end_time": "2021-01-14T14:46:18.028359",
     "exception": false,
     "start_time": "2021-01-14T14:46:18.006066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. Deep Learning Algorithm Implementation & Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-14T14:46:18.077198Z",
     "iopub.status.busy": "2021-01-14T14:46:18.076244Z",
     "iopub.status.idle": "2021-01-14T14:53:57.735140Z",
     "shell.execute_reply": "2021-01-14T14:53:57.734546Z"
    },
    "id": "-wOWo4-GyJgb",
    "outputId": "3d807070-455e-45c2-ac71-0bb127e78cc0",
    "papermill": {
     "duration": 459.683882,
     "end_time": "2021-01-14T14:53:57.735264",
     "exception": false,
     "start_time": "2021-01-14T14:46:18.051382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Compiling the neural network\n",
    "\n",
    "model_dl.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Fitting to the model\n",
    "\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau #Import callback functions\n",
    "earlystop=EarlyStopping(patience=10) #Monitor the performance. If it dips, then stop training\n",
    "learning_rate_reduce=ReduceLROnPlateau(monitor=\"val_acc\",min_lr=0.001) #Change learning rate if not performing good enough\n",
    "callbacks=[earlystop,learning_rate_reduce]\n",
    "\n",
    "model_dl.fit(asl_train_ds, validation_data=asl_test_ds, callbacks=callbacks, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-14T14:54:03.565302Z",
     "iopub.status.busy": "2021-01-14T14:54:03.564167Z",
     "iopub.status.idle": "2021-01-14T14:54:03.769208Z",
     "shell.execute_reply": "2021-01-14T14:54:03.769779Z"
    },
    "id": "MSMKnt-FyJgb",
    "outputId": "5d14686e-0cab-412a-d534-cef32e96d591",
    "papermill": {
     "duration": 1.132933,
     "end_time": "2021-01-14T14:54:03.769957",
     "exception": false,
     "start_time": "2021-01-14T14:54:02.637024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We´ll use any image sample from the Kaggle dataset to test it \n",
    "import cv2\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "#Creating a dictionary to map each of the indexes to the corresponding number or letter\n",
    "\n",
    "dict = {0:\"0\",1:\"1\",2:\"2\",3:\"3\",4:\"4\",5:\"5\",6:\"6\",7:\"7\",8:\"8\",9:\"9\",10:\"a\",11:\"b\",12:\"c\",13:\"d\",14:\"e\",15:\"f\",16:\"g\",\n",
    "        17:\"h\",18:\"i\",19:\"j\",20:\"k\",21:\"l\",22:\"m\",23:\"n\",24:\"o\",25:\"p\",26:\"q\",27:\"r\",28:\"s\",29:\"t\",30:\"u\",31:\"v\",32:\"w\",\n",
    "        33:\"x\",34:\"y\",35:\"z\"}\n",
    "\n",
    "#Predicting images\n",
    "\n",
    "#img = cv2.   (\"/content/drive/MyDrive/Colab Notebooks/Hand gesture recognition/hand1_a_bot_seg_1_cropped.jpeg\")\n",
    "\n",
    "#Predicting images\n",
    "\n",
    "img = load_img(\"/content/drive/MyDrive/Colab Notebooks/Hand gesture recognition/frame.jpg\", target_size=(img_width, img_height))\n",
    "x = img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "image = np.vstack([x])\n",
    "classes = model_dl.predict(image, batch_size=batch_size)\n",
    "predicted_class = np.argmax(classes)\n",
    "classes=predicted_class\n",
    "\n",
    "probabilities = model_dl.predict(image)\n",
    "probabilities_formatted = list(map(\"{:.2f}%\".format, probabilities[0]*100))\n",
    "\n",
    "print(probabilities_formatted) #displaying matrix prediction position\n",
    "print(f'The predicted image corresponds to \"{dict[classes.item()]}\" with {probabilities_formatted[classes.item()]} probability.') #displaying matrix prediction position name (number or letter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_QdzO6j5-qe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "duration": 507.93792,
   "end_time": "2021-01-14T14:54:06.569024",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-14T14:45:38.631104",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
